{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "7NZ77Rekq0jR"
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import numpy as np\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "1E9TYh4tq6bk"
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "   \n",
    "    # input  text ='이 SF영화 재미^^;; 없는데.....왜 7점이지???'\n",
    "    # output text ='$이_SF영화_재미_없는데_왜_7점이지$'\n",
    "    \n",
    "    non_alpha_numeric_hangul = re.compile('[^0-9a-zA-Z\\u3131-\\u3163\\uac00-\\ud7a3]')\n",
    "    SS = '$'  # Sentence Separator\n",
    "    \n",
    "    t = non_alpha_numeric_hangul.sub('_', text)\n",
    "    text = re.sub(r'_+', '_', t)\n",
    "    return SS+text+SS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "RgT0jfbsrAvK"
   },
   "outputs": [],
   "source": [
    "def prepare_data_file(FILE_PATH):\n",
    "    \n",
    "    # file load from URL\n",
    "    with urllib.request.urlopen(FILE_PATH) as f:\n",
    "        lines = f.read().decode('utf-8').split('\\n')\n",
    "\n",
    "    data, target = [], []\n",
    "    for l in lines[1:]:   # 첫번째 줄은 skip\n",
    "        try:\n",
    "            _, text, label = l.strip().split('\\t')   # ID\\treview\\tlabel \n",
    "        except ValueError:\n",
    "            pass\n",
    "        text = text.strip()\n",
    "        if text == '': continue\n",
    "        data.append(preprocess_text(text))\n",
    "        target.append(int(label))\n",
    "            \n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "Aeooi3Nyre5j"
   },
   "outputs": [],
   "source": [
    "def extract_features(data, MAX_FEATURES):\n",
    "    \n",
    "    # 학습데이터 data로부터 bigram feature 추출\n",
    "    # MAX_FEATURES 만큼만 feature로 사용\n",
    "    # 발생 빈도로 정렬\n",
    "    \n",
    "    FEATURES = dict()\n",
    "    features_dict = dict()\n",
    "    \n",
    "    for line in data:\n",
    "        uni_list = list(line)\n",
    "        bi_list = [''.join(uni_list[z:z+2]) for z in range(0, len(uni_list)-1)]\n",
    "        for bigram in bi_list:\n",
    "            if bigram in FEATURES:\n",
    "                FEATURES[bigram] += 1\n",
    "            else:\n",
    "                FEATURES[bigram] = 1\n",
    "    \n",
    "    features_list = [(x, f) for (x, f) in FEATURES.items()]\n",
    "    features_list.sort(reverse=True, key=lambda z:z[1])\n",
    "    \n",
    "    for (idx, (x, y)) in enumerate(features_list[:MAX_FEATURES]):\n",
    "        features_dict[x] = idx\n",
    "\n",
    "    return features_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "pA-k0EpHrnjI"
   },
   "outputs": [],
   "source": [
    "def make_feature_vector(feature_set, data, target):\n",
    "\n",
    "    fv_base = [0 for _ in range(0, len(feature_set))]\n",
    "    feature_list = []\n",
    "    for (x, label) in zip(data, target):\n",
    "        uni_list = list(x)\n",
    "        fv = fv_base[:]\n",
    "        bi_list = [''.join(uni_list[z:z+2]) for z in range(0, len(uni_list)-1)]\n",
    "        for bigram in bi_list: \n",
    "            if bigram in feature_set:\n",
    "                fv[feature_set[bigram]] = 1\n",
    "                \n",
    "        feature_list.append(fv + [label])\n",
    "    feature_list = np.array(feature_list)\n",
    "    np.random.shuffle(feature_list)\n",
    "    \n",
    "    return feature_list[:, :-1], feature_list[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jqjFt4stryKH",
    "outputId": "816bea33-def3-4766-e8d1-b7a318bc3b3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepare_data_file START...\n",
      "prepare_data_file END...\n"
     ]
    }
   ],
   "source": [
    "# NAVER MOVIE REVIEW corpus로부터 데이터 loading\n",
    "TRAIN_FILE = 'https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt'\n",
    "TEST_FILE = 'https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt'\n",
    "\n",
    "print('prepare_data_file START...')\n",
    "train_data, train_target = prepare_data_file(TRAIN_FILE)\n",
    "test_data, test_target = prepare_data_file(TEST_FILE)\n",
    "print('prepare_data_file END...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "H3fXgtw8uz9n",
    "outputId": "376dc21f-ae5c-447c-e1ae-f2449f703a6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extract_features START...\n",
      "extract_features END...\n"
     ]
    }
   ],
   "source": [
    "# Bigram Feature 추출\n",
    "print('extract_features START...')\n",
    "MAX_FEATURES = 500  # 사용할 feature 개수\n",
    "feature_set = extract_features(train_data, MAX_FEATURES)\n",
    "with open('features.out', 'w', encoding='utf8') as fo:\n",
    "    fo.write('\\n'.join([x+'\\t'+str(idx) for x, idx in feature_set.items()]))\n",
    "    \n",
    "print('extract_features END...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tJxmozlPu9Zk",
    "outputId": "fc912b93-8eb0-4aa3-9452-de5c768a5a60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make_feature_vector START...\n",
      "make_feature_vector END...\n"
     ]
    }
   ],
   "source": [
    "# 입력 파일을 feature vector로 변환\n",
    "print('make_feature_vector START...')\n",
    "x_train, y_train = make_feature_vector(feature_set, train_data, train_target)\n",
    "x_test,  y_test  = make_feature_vector(feature_set, test_data, test_target)\n",
    "print('make_feature_vector END...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wE_mV3R551dt",
    "outputId": "e500c6cb-1170-45da-831c-0afe17920448"
   },
   "outputs": [],
   "source": [
    "# Machine Learning Tool을 사용하여 학습\n",
    "\n",
    "#from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#print('train START...')\n",
    "#model = MultinomialNB()\n",
    "#model.fit(x_train, y_train)\n",
    "#print('train END...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jcuPv5ZZPUmI",
    "outputId": "0c014105-265d-411d-db18-c1220b7bdc10"
   },
   "outputs": [],
   "source": [
    "# Model의 정확도 평가\n",
    "#print('eval START...')\n",
    "#print(\"훈련 세트 정확도: {:.3f}\".format(model.score(x_train, y_train)))  # Eval\n",
    "#print(\"테스트 세트 정확도: {:.3f}\".format(model.score(x_test, y_test)))  # Eval\n",
    "#print('eval END...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ggYv4CU6y58n",
    "outputId": "97f88756-d6f9-4ccd-806a-89b07481e8df"
   },
   "outputs": [],
   "source": [
    "# 수행해 보기\n",
    "#text = '최고의 명작... 왜 이제서야 이 영화를 봤을꼬??'   \n",
    "#text = preprocess_text(text)\n",
    "#x_test, _ = make_feature_vector(feature_set, [text], [None])\n",
    "#result = model.predict(x_test)\n",
    "#print(text, '==> ', ['Negative', 'Positive'][result[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train START...\n",
      "train END...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "print('train START...')\n",
    "tree = DecisionTreeClassifier(random_state=0)\n",
    "tree.fit(x_train, y_train)\n",
    "print('train END...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval START...\n",
      "훈련 세트 정확도: 0.979\n",
      "테스트 세트 정확도: 0.694\n",
      "eval END...\n"
     ]
    }
   ],
   "source": [
    "print('eval START...')\n",
    "print(\"훈련 세트 정확도: {:.3f}\".format(tree.score(x_train, y_train)))\n",
    "print(\"테스트 세트 정확도: {:.3f}\".format(tree.score(x_test, y_test)))\n",
    "print('eval END...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$최고의_명작_왜_이제서야_이_영화를_봤을꼬_$ ==>  Positive\n"
     ]
    }
   ],
   "source": [
    "text = '최고의 명작... 왜 이제서야 이 영화를 봤을꼬??'   \n",
    "text = preprocess_text(text)\n",
    "x_test, _ = make_feature_vector(feature_set, [text], [None])\n",
    "result = tree.predict(x_test)\n",
    "print(text, '==> ', ['Negative', 'Positive'][result[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NaverMovieReview_sklearn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
